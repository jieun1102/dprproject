{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN24CiYSd6G24dAOlY2WM7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jieun1102/dprproject/blob/main/dprproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이미지 파일이 있는 디렉토리 설정\n",
        "sea_dir = './dprproject/data/sea'\n",
        "forest_dir = './dprproject/data/forest'\n",
        "\n",
        "# 이미지 파일 불러오기 및 크기 조정\n",
        "width = 128\n",
        "height = 128\n",
        "\n",
        "sea_images = []\n",
        "for filename in os.listdir(sea_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(os.path.join(sea_dir, filename))\n",
        "        img = img.resize((width, height))  # 이미지 크기 조정\n",
        "        sea_images.append(img)\n",
        "\n",
        "forest_images = []\n",
        "for filename in os.listdir(forest_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(os.path.join(forest_dir, filename))\n",
        "        img = img.resize((width, height))  # 이미지 크기 조정\n",
        "        forest_images.append(img)\n",
        "\n",
        "# 이미지 데이터 확인\n",
        "plt.imshow(sea_images[3])\n",
        "plt.show()\n",
        "plt.imshow(forest_images[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_pCxWn8TTyvy",
        "outputId": "ece446c2-3c1a-4d77-c5df-3e8be402905f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-81c76b4f8605>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 이미지 크기 조정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mforest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2154\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m             \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터를 numpy 배열로 변환\n",
        "sea_data = np.array([np.array(img) for img in sea_images])\n",
        "forest_data = np.array([np.array(img) for img in forest_images])\n",
        "\n",
        "# 레이블 생성\n",
        "sea_labels = np.zeros(len(sea_data))\n",
        "forest_labels = np.ones(len(forest_data))\n",
        "\n",
        "# 데이터 결합\n",
        "X = np.concatenate((sea_data, forest_data), axis=0)\n",
        "y = np.concatenate((sea_labels, forest_labels), axis=0)\n",
        "\n",
        "# 데이터 형태 확인\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "0IE6y8AgVctJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습셋과 테스트셋 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "IH30Y1JMWkkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-waIxFfiXlJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKzrK5etVg-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 정규화\n",
        "images = images / 255.0\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분리\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "U7plRXybF64Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# CNN 모델 정의\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "9FD4a4ptZf4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "-69-lcIRHzzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "u36nzgXlH0Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 시각화\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5FZUZnlnH1kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# 이미지 파일이 있는 디렉토리 설정\n",
        "sea_dir = './dprproject/data/sea'\n",
        "forest_dir = './dprproject/data/forest'\n",
        "\n",
        "# 이미지 파일 불러오기 및 크기 조정\n",
        "width = 128\n",
        "height = 128\n",
        "\n",
        "sea_images = []\n",
        "for filename in os.listdir(sea_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(os.path.join(sea_dir, filename))\n",
        "        img = img.resize((width, height))  # 이미지 크기 조정\n",
        "        sea_images.append(img)\n",
        "\n",
        "forest_images = []\n",
        "for filename in os.listdir(forest_dir):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "        img = Image.open(os.path.join(forest_dir, filename))\n",
        "        img = img.resize((width, height))  # 이미지 크기 조정\n",
        "        forest_images.append(img)\n",
        "\n",
        "# 이미지 데이터를 numpy 배열로 변환\n",
        "sea_data = np.array([np.array(img) for img in sea_images])\n",
        "forest_data = np.array([np.array(img) for img in forest_images])\n",
        "\n",
        "# 레이블 생성\n",
        "sea_labels = np.zeros(len(sea_data))\n",
        "forest_labels = np.ones(len(forest_data))\n",
        "\n",
        "# 데이터 결합\n",
        "X = np.concatenate((sea_data, forest_data), axis=0)\n",
        "y = np.concatenate((sea_labels, forest_labels), axis=0)\n",
        "\n",
        "# 데이터 정규화\n",
        "X = X / 255.0\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN 모델 정의\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "#모델 학습\n",
        "\n",
        "#이미지 예측하는 코드 추가\n",
        "# 이미지 파일 경로 설정\n",
        "image_path = 'https://gscaltexmediahub.com/wp-content/uploads/2023/05/the-day-of-ocean-2023_1.png'  # 예시 이미지 파일 경로\n",
        "\n",
        "# 이미지 불러오기 및 크기 조정\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((128, 128))  # 모델의 입력 크기와 일치하도록 크기 조정\n",
        "img_array = np.array(img) / 255.0  # 이미지 데이터를 정규화\n",
        "\n",
        "# 모델 예측\n",
        "prediction = model.predict(np.expand_dims(img_array, axis=0))\n",
        "\n",
        "# 결과 출력\n",
        "#prediction[0][0]은 바다 클래스에 대한 예측 확률, 두번째 원소는 수플래스에 대한 예측확률\n",
        "if prediction[0][0] > prediction[0][1]:\n",
        "    print(\"해당 이미지는 바다입니다.\")\n",
        "else:\n",
        "    print(\"해당 이미지는 숲입니다.\")\n",
        "\n",
        "# 이미지 출력\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gQaeSF9Xm-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1dKzAEiYRzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}